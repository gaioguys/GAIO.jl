{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in die Parallelisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cores: 1 and Number of Workers: 1    ---     11.859163 seconds (385.42 k allocations: 19.520 MiB, 0.09% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141582132"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Beispiel 0: Approximation von Pi mit nur einem Prozess\n",
    "using Distributed\n",
    "\n",
    "# Teste wie viele Prozesse arbeiten\n",
    "print(\"Number of Cores: \", nprocs(),\" and Number of Workers: \", nworkers(), \"    ---    \")\n",
    "\n",
    "# define a function that counts the number of points falling inside the circle\n",
    "@everywhere function points_inside_circle(n)\n",
    "    n_in = 0\n",
    "    for i = 1:n\n",
    "        x, y = rand(), rand()\n",
    "        n_in += (x*x + y*y) <= 1\n",
    "    end\n",
    "    return n_in\n",
    "end\n",
    "\n",
    "# define a function wrapper that computes the approximation of pi in parallel\n",
    "@everywhere function pi_p(n)    \n",
    "    p = nworkers()\n",
    "    n_in = @distributed (+) for i = 1:p\n",
    "        points_inside_circle(n/p)\n",
    "    end\n",
    "    return 4 * n_in / n\n",
    "end\n",
    "\n",
    "\n",
    "@time pi_p(1_000_000_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erste Schritte"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### mehrere Prozesse in Julia starten ###\n",
    "\n",
    "# Julia beim Start mitteilen, wie viele Prozesse zu starten sind (hier 4 bei 4 Kernen)\n",
    "-p 4\n",
    "# Prozesse On the Fly hinzufügen (hier 3)\n",
    "using Distributed\n",
    "addprocs(3)\n",
    "\n",
    "#### Eine Variable für alle Prozesse verfügbar machen ###\n",
    "\n",
    "@everywhere x = 12345\n",
    "x0 = 12345\n",
    "@everywhere x = x0 # funktioniert nicht, da x0 lokal ist\n",
    "@everywhere x = $x0 # funktioniert; der x0-Wert wird kopiert\n",
    "\n",
    "#### Eine Funktion für alle Prozesse definieren ###\n",
    "\n",
    "@everywhere function myFunction()\n",
    "    printIn(\"Hallo!\")\n",
    "end\n",
    "\n",
    "\n",
    "myid() # Gibt ID des Prozesses zurück\n",
    "remotecall() # Aufgabe von einem bestimmten Prozess ausführen lassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cores: 4 and Number of Workers: 3    ---    "
     ]
    }
   ],
   "source": [
    "## Beispiel 1: Füge drei neue Prozesse hinzu \n",
    "using Distributed\n",
    "addprocs(3)\n",
    "print(\"Number of Cores: \", nprocs(),\" and Number of Workers: \", nworkers(), \"    ---    \")\n",
    "# Somit haben wir einen Leader (immer ID 1) und n Worker verteilt auf n+1 Prozesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| I have the ID: 2 with PID: 17760 and HOST: MacBook-3.local || I have the ID: 3 with PID: 17761 and HOST: MacBook-3.local || I have the ID: 4 with PID: 17762 and HOST: MacBook-3.local |"
     ]
    }
   ],
   "source": [
    "## Beispiel 2: Rufe Informationen über die Prozesse ab\n",
    "for i in workers()\n",
    "    id, pid, host = fetch(@spawnat i (myid(), getpid(), gethostname()))\n",
    "    print(\"| I have the ID: \", id, \" with PID: \", pid, \" and HOST: \", host, \" |\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prozesse ausführen\n",
    "\n",
    "Wichtige Funktionen: \n",
    "* $remotecall()$ - Aufgabe von einem bestimmten Prozess ausführen lassen. (Asynchroner Aufruf, kein Blocking, Return sofort)\n",
    "* $fetch()$ - Ergebnis abholen. (Julia verwendet eine Future-Referenz. Diese ist sofort verfügbar, das Ergebnis muss aber abgholt werden.)\n",
    "* $remotecall$_$fetch()$ - Synchroner Aufruf inkl. Abholung des Ergebnisses. (Kombiniert $remotecal()$ und $fetch()$.)\n",
    "* $@spawn$ - Aufgaben an andere Prozesse senden\n",
    "* $@spawnat$ - Aufgabe an einen bestimmten Prozess senden\n",
    "\n",
    "### Beispiele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Beispiel 3: Prozess mit ID 2 soll 1 + 3 rechnen\n",
    "\n",
    "result = remotecall(+, 2, 1, 3) \n",
    "\n",
    "fetch(result) # Ergebnis muss abgeholt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 Array{Float64,2}:\n",
       " 1.08486  1.45546  1.89077  1.21451\n",
       " 1.22418  1.51434  1.64637  1.0909\n",
       " 1.9326   1.66997  1.31625  1.95114"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Beispiel 4: Prozess 2 nutzt Ergebnis von Prozess 4\n",
    "\n",
    "result = remotecall(rand, 4, 3, 4) # Prozess 4 erzeugt eine 3x4 Zufallsmatrix\n",
    "s = @spawnat 2 1 .+ fetch(result)  # Prozess 2 benutzt das Ergebnis von 4 und hängt 1. davor\n",
    "fetch(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.381167 seconds (83.80 k allocations: 4.139 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141593112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Beispiel 5: Approximation von Pi mit mehreren Prozessen\n",
    "# Mit @distributed wird die for-loop in der zweiten Funktion verteilt ausgeführt.\n",
    "using Distributed\n",
    "# define a function that counts the number of points falling inside the circle\n",
    "@everywhere function points_inside_circle(n)\n",
    "    n_in = 0\n",
    "    for i = 1:n\n",
    "        x, y = rand(), rand()\n",
    "        n_in += (x*x + y*y) <= 1\n",
    "    end\n",
    "    return n_in\n",
    "end\n",
    "\n",
    "# define a function wrapper that computes the approximation of pi in parallel\n",
    "@everywhere function pi_p(n)    \n",
    "    p = nworkers()\n",
    "    n_in = @distributed (+) for i = 1:p \n",
    "        points_inside_circle(n/p)\n",
    "    end\n",
    "    return 4 * n_in / n\n",
    "end\n",
    "\n",
    "\n",
    "@time pi_p(1_000_000_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man hier sehen  kann, halbiert sich die Berechnungszeit fast, indem man verteilt auf vier Prozesse rechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in das Paket Distributed Arrays\n",
    "Große Berechnungen sind meist aus großen Arrays aufgebaut.\n",
    "In diesem Fall macht es Sinn, die Arrays unter verschiedenen Prozessen aufzuteilen.\n",
    "Indem die Speicherkapazitäten von verschiedenen Maschinen genutzt werden können, können so unter anderem Arrays berechnet werden, die sonst zu groß wären.\n",
    "Jeder Prozess kann den ihm zugewiesenen Teil des Arrays lesen und überschreiben. Gleichzeitig kann jeder Prozess das vollständige Array lesen (read-only).\n",
    "\n",
    "In Julia werden Distributed Arrays durch den \"DArray\"-Typ beschrieben. \n",
    "* Elementtyp und Dimensionen sind wie bei normalen Arrays\n",
    "* Enthaltene Daten werden durch eine Aufteilung der Indexmenge in eine bestimmte Anzahl von Blöcken in jeder Dimension aufgeteilt\n",
    "\n",
    "Vorteil:\n",
    "* When dividing data among a large number of processes, one often sees diminishing returns in performance. Placing DArrays on a subset of processes allows multiple DArray computations to happen at once, with a higher ratio of work to communication on each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiele für Distributed Arrays:\n",
    "* Julia übernimmt hier die gesamte Arbeit: Die einzelnen Matrixelemente sind auf die verschiedenen Prozesse verteilt und auch initialisiert."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dzeros(100,100,10)\n",
    "dones(100,100,10)\n",
    "drand(100,100,10)\n",
    "drandn(100,100,10)\n",
    "dfill(x,100,100,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Für mehr Kontrolle:\n",
    "* Spezifizifikation eines bestimmten Prozesses für eine Aufgabe\n",
    "* Festlegung, wie die Daten aufgeteilt werden sollen\n",
    "\n",
    "Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×100 DArray{Float64,2,Array{Float64,2}}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#= \n",
    "Second argument: Array should be created on the first three workers.\n",
    "Third argument: Specify a distribution; the nth element of this array specifies\n",
    "how many pieces dimension n should be divided into.\n",
    "HERE: The first dimension will not be divided, the second dimension will be divided into 4 pieces.\n",
    "Therefore each local chunk will be of size (100,25).\n",
    "=#\n",
    "dzeros((100,100), workers()[1:3], [1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hilfreiche Funktionen:\n",
    "\n",
    "Note: Indexing a DArray (square brackets) with ranges of indices always creates a SubArray, not copying any data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "localpart(d::DArray)       # Teil des Arrays, der dem lokalen Prozess zugewiesenen ist\n",
    "    d[:L]                  # Teil von d, der dem lokalen Prozess zugewiesenen ist\n",
    "    d[:L] = v              # setze v als den Teil von d, der dem lokalen Prozess zugewiesenen ist\n",
    "localindices(d::DArray)    # Indizes des lokalen Teils des Arrays (Tupel)\n",
    "\n",
    "convert(Array, d::DArray)  # lokaler Prozess soll ein Distributed Array komplett bearbeiten\n",
    "distribute(a::Array)       # Umwandlung eines lokalen Arrays in ein Distributed Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisierung\n",
    "\n",
    "* $init$ - vom Programmierer bereitzustellen; bekommt ein Tupel von Index-Bereichen übergeben, für die das Array dann innerhalb der Init-Funktion initialisiert wird; Init-Funktion initialisiert also lokale Bereiche des Distributed Arrays\n",
    "* $dims$ - Dimension des Distributed Arrays \n",
    "* $procs$ - Optional: Spezifiziert einen Vektor von Prozess IDs, die genutzt werden sollen\n",
    "* $dist$ - Optional: Integer Vektor, der angibt wie der Distributed Array in jeder Dimension unter den Prozessen aufgeteilt werden soll"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DArray(init, dims[, procs, dist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Verteilte Zufallsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×4 Array{Float64,2}:\n",
       " 0.375114   0.515236   0.544062  0.807627\n",
       " 0.913663   0.382798   0.974972  0.919571\n",
       " 0.223225   0.170889   0.637931  0.136496\n",
       " 0.886466   0.524885   0.5522    0.838163\n",
       " 0.156507   0.850004   0.910517  0.0415769\n",
       " 0.504012   0.30831    0.765573  0.956131\n",
       " 0.420482   0.918328   0.523361  0.0341088\n",
       " 0.9587     0.981585   0.630585  0.599726\n",
       " 0.0495685  0.0978773  0.82137   0.422337\n",
       " 0.918235   0.248038   0.903477  0.343083"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere using DistributedArrays\n",
    "# ------------------------------------\n",
    "#=Erzeuge eine verteilte Zufallsmatrix und gib den Teil zurück, für den Prozess 2 verantwortlich ist.\n",
    "Mehrmaliges Hintereinanderausführen führt zu einer immer feineren, automatischen Aufteilung der Matrix,\n",
    "da mehr Prozesse hinzugefügt werden.=#\n",
    "\n",
    "d = drand(10,10);\n",
    "r = @spawnat 2 begin\n",
    "    localpart(d)\n",
    "end\n",
    "fetch(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Praktische: \n",
    "Julia versteckt die gesamte Kommunikation vor dem Benutzer. Will man z.B. die Summe aller Elemente der Matrix berechnen, so ruft man einfach $sum(d)$ auf. Das liefert direkt das Ergebnis. Julia summiert dabei mit jedem einzelnen Prozess alle Elemente des Teilarray auf. Anschließend werden dann alle Teilergebnisse zur Gesamtsumme addiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.187323 seconds (1.59 M allocations: 91.722 MiB, 1.62% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.68024169298725"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=Erzeuge eine verteilte Zufallsmatrix.=#\n",
    "\n",
    "d = drand(10,10);\n",
    "\n",
    "@time sum(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Julia mit Julia (funktioniert hier leider noch nicht)\n",
    "\n",
    "http://mathemartician.blogspot.com/2012/07/julia-set-in-julia.html\n",
    "\n",
    "zum Nachlesen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeException",
     "evalue": "TaskFailedException:\nOn worker 2:\nTypeError: in typeassert, expected Int64, got Type{Int64}\nparJuliaInit at ./In[21]:24\n#construct_localparts#5 at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:118\nconstruct_localparts at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:118\n#104 at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/process_messages.jl:294\nrun_work_thunk at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/process_messages.jl:79\nmacro expansion at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/process_messages.jl:294 [inlined]\n#103 at ./task.jl:358\nStacktrace:\n [1] remotecall_fetch(::Function, ::Distributed.Worker, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:390\n [2] remotecall_fetch(::Function, ::Distributed.Worker, ::Function, ::Vararg{Any,N} where N) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:382\n [3] remotecall_fetch(::Function, ::Int64, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:417\n [4] remotecall_fetch at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:417 [inlined]\n [5] macro expansion at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:88 [inlined]\n [6] (::DistributedArrays.var\"#1#3\"{Tuple{Int64,Int64},typeof(parJuliaInit),Tuple{Int64,Int64},Array{Int64,2},Array{Tuple{UnitRange{Int64},UnitRange{Int64}},2},Array{Array{Int64,1},1},Array{DataType,1},Int64})() at ./task.jl:358\n\n...and 2 more exception(s).\n",
     "output_type": "error",
     "traceback": [
      "TaskFailedException:\nOn worker 2:\nTypeError: in typeassert, expected Int64, got Type{Int64}\nparJuliaInit at ./In[21]:24\n#construct_localparts#5 at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:118\nconstruct_localparts at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:118\n#104 at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/process_messages.jl:294\nrun_work_thunk at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/process_messages.jl:79\nmacro expansion at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/process_messages.jl:294 [inlined]\n#103 at ./task.jl:358\nStacktrace:\n [1] remotecall_fetch(::Function, ::Distributed.Worker, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:390\n [2] remotecall_fetch(::Function, ::Distributed.Worker, ::Function, ::Vararg{Any,N} where N) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:382\n [3] remotecall_fetch(::Function, ::Int64, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:417\n [4] remotecall_fetch at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Distributed/src/remotecall.jl:417 [inlined]\n [5] macro expansion at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:88 [inlined]\n [6] (::DistributedArrays.var\"#1#3\"{Tuple{Int64,Int64},typeof(parJuliaInit),Tuple{Int64,Int64},Array{Int64,2},Array{Tuple{UnitRange{Int64},UnitRange{Int64}},2},Array{Array{Int64,1},1},Array{DataType,1},Int64})() at ./task.jl:358\n\n...and 2 more exception(s).\n",
      "",
      "Stacktrace:",
      " [1] sync_end(::Array{Any,1}) at ./task.jl:316",
      " [2] macro expansion at ./task.jl:335 [inlined]",
      " [3] DArray(::Tuple{Int64,Int64}, ::Function, ::Tuple{Int64,Int64}, ::Array{Int64,2}, ::Array{Tuple{UnitRange{Int64},UnitRange{Int64}},2}, ::Array{Array{Int64,1},1}) at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:83",
      " [4] DArray(::Function, ::Tuple{Int64,Int64}, ::Array{Int64,1}, ::Array{Int64,1}) at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:177",
      " [5] DArray at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:184 [inlined]",
      " [6] DArray(::Function, ::Tuple{Int64,Int64}) at /Users/alfonshilmer/.julia/packages/DistributedArrays/UZMDF/src/darray.jl:186",
      " [7] top-level scope at In[21]:34"
     ]
    }
   ],
   "source": [
    "#DistributedArrays, WIDTH, HEIGHT und MAXITER sind global\n",
    "@everywhere WIDTH = 1000\n",
    "@everywhere HEIGHT = 500\n",
    "@everywhere MAXITER = 100\n",
    "\n",
    "#Images ist lokal\n",
    "using Images\n",
    "\n",
    "# Julia-Funktion\n",
    "@everywhere function julia(z, maxiter::Int64)\n",
    "    c = -0.8 + 0.156im\n",
    "    for n = 1:maxiter\n",
    "        if abs(z) > 2.0\n",
    "            return n-1\n",
    "        end\n",
    "        z = z^2 + c\n",
    "    end\n",
    "    return maxiter\n",
    "end\n",
    "\n",
    "# Init-Funktion zum Anlegen des Arrays\n",
    "@everywhere function parJuliaInit(I)\n",
    "    e = (size(I[1], 1), size(I[2], 1))\n",
    "    m = Array(Int, e)\n",
    "    xMin=I[2][1]\n",
    "    yMin=I[1][1]\n",
    "    \n",
    "    for x = I[2], y = I[1]\n",
    "        c = complex((x - WIDTH/2) / (HEIGHT/2), (y - HEIGHT/2) / (HEIGHT/2))\n",
    "        m[y - yMin + 1, x - xMin + 1] = julia(c, MAXITER)\n",
    "    end\n",
    "    return m\n",
    "end\n",
    "\n",
    "# Distributed Array anlegen\n",
    "Dm = DArray(parJuliaInit, (HEIGHT, WIDTH))\n",
    "\n",
    "# Distributed Array auf den lokalen Prozess holen\n",
    "#m = convert(Array, Dm)\n",
    "\n",
    "#Bild als PNG speichern\n",
    "#imwrite(grayim(transpose(m)/(1.0*MAXITER)),\"juliaset.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
